Implement the **SARSA** algorithm to estimate Q-values for a given set of deterministic transitions using greedy action selection.

- All Q-values are initialized to zero.
- Each episode starts from a given initial state.
- The episode ends when it reaches the $terminal$ state or when the number of steps exceeds $maxsteps$.
- Changes made to Q-values are persistent across episodes.
