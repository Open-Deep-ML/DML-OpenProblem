import numpy as np


def calculate_params(dist1: np.ndarray, dist2: np.ndarray) -> tuple[np.ndarray,...]:
    return np.mean(dist1,axis=1), np.cov(dist1), \
        np.mean(dist2,axis=1), np.cov(dist2)

def multivariate_kl_divergence(mu_p:np.ndarray, Cov_p:np.ndarray, 
                               mu_q:np.ndarray, Cov_q:np.ndarray) -> float:
    
    def trace(x: np.ndarray) -> float:
        return np.diag(x).sum()
    
    p = Cov_p.shape[0]
    return float(1/2 * (
        np.log(np.linalg.det(Cov_q)/np.linalg.det(Cov_p)) \
        - p + (mu_p-mu_q).T @ np.linalg.inv(Cov_q) @ (mu_p-mu_q) \
        + trace(np.linalg.inv(Cov_q) @ Cov_p)
    ).round(5))


def test_multivariate_kl_divergence():
    # Test 1
    Px, Qx = (np.array([[-1.10823602,  0.59047503, -1.28836549, -0.73620719,  0.09297073,
            0.22682387,  0.07868853, -0.76153383,  0.00923222, -0.96858733],
            [ 0.61326346, -1.81557987, -1.90980858, -0.83686333,  1.02380289,
            0.8201234 ,  0.47230038,  1.23401309,  0.83863829,  0.58327546],
            [ 0.11753089, -0.6688544 ,  0.22664275,  0.36211424,  1.27036865,
            0.85658812,  0.90656472,  0.61665432,  0.64608009, -1.49203659],
            [ 0.44536947, -0.19875256, -0.660614  , -0.44018991,  0.23761623,
            0.59295044,  0.56643128,  0.6524627 ,  0.2249772 , -0.72461754]]),
        np.array([[  1.75135976,   4.61276384,  15.30413416,  -5.99894353,
            -4.69007769,   7.73412182,   4.99673152, -19.16128094,
            2.03262704,  19.27716282],
            [ -0.90920165,   9.16261654,   9.30026629,  -3.27268949,
            15.2881266 ,   3.26775188,   5.52151153,  22.46221005,
            5.54312996,   4.12412513],
            [ -3.17744585,  -8.49069278, -11.29824737,  18.35998073,
            4.06025687,  12.95655264,   7.86052982,  -0.55356645,
            4.35538644,   0.17841619],
            [  3.76646367,  -4.28324786,   4.11652827,  -8.73836953,
            13.88560715,   4.67098934, -12.64946117,  -5.13094827,
            0.92036673,  -7.12158446]]))
    expected_kldiv = 9.798905
    mu1, cov1, mu2, cov2 = calculate_params(Px, Qx)
    assert multivariate_kl_divergence(mu1,cov1,mu2,cov2) == expected_kldiv, 'Test 1 failed'

    # Test 2
    Px, Qx = (np.array([[-1.81686496,  1.33241772, -0.87456391,  1.35687399, -0.67848962,
            0.02259325, -0.41767687,  0.86570228],
            [ 0.62453178, -0.52656437, -0.33139549,  0.42297485, -0.87139157,
            0.54532539,  2.21191033,  1.18464445],
            [ 0.99921409,  0.13376797,  1.21645871, -1.25046398, -0.22635466,
            1.25164884, -1.45502235,  0.50679063]]),
        np.array([[ -4.99296366, -11.4314525 ,   3.84772435,   3.91530916,
            3.74013836,   3.62324783,   2.80447139,   2.20821923],
            [ -0.28726012,   6.23386886,  -1.9413503 ,  -8.66484157,
            7.78345826,  -6.3642635 ,  -3.16064884,   6.01129742],
            [ -1.27119644,  -4.20216927,   3.43134959,  -0.59611411,
            -1.00232576,  -0.74840254,   4.45956856,  -5.56414496]]))
    expected_kldiv = 3.1197
    mu1, cov1, mu2, cov2 = calculate_params(Px, Qx)
    assert multivariate_kl_divergence(mu1,cov1,mu2,cov2) == expected_kldiv, 'Test 2 failed'

    print('All tests passed')

    
if __name__ == "__main__":
    test_multivariate_kl_divergence()